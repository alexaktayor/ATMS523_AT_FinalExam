{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b6db150a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output: /home/alexakt2/.jupyter/https:/data/ghcn_il_top4_daily.parquet\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd, numpy as np\n",
    "from pathlib import Path\n",
    "import fsspec\n",
    "\n",
    "S3_STATIONS_TXT   = \"s3://noaa-ghcn-pds/ghcnd-stations.txt\"\n",
    "S3_INVENTORY_TXT  = \"s3://noaa-ghcn-pds/ghcnd-inventory.txt\"\n",
    "S3_BY_STATION     = \"s3://noaa-ghcn-pds/csv/by_station/{id}.csv\"\n",
    "STOR = {\"anon\": True}\n",
    "\n",
    "OUTDIR = Path('../data'); OUTDIR.mkdir(parents=True, exist_ok=True)\n",
    "OUT_PARQUET = OUTDIR / 'ghcn_il_top4_daily.parquet'\n",
    "print('Output:', OUT_PARQUET.resolve())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "37f076af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(            ID  LATITUDE  LONGITUDE  ELEVATION STATE                   NAME  \\\n",
       " 0  ACW00011604   17.1167   -61.7833       10.1        ST JOHNS COOLIDGE FLD   \n",
       " 1  ACW00011647   17.1333   -61.7833       19.2                     ST JOHNS   \n",
       " 2  AE000041196   25.3330    55.5170       34.0          SHARJAH INTER. AIRP   \n",
       " 3  AEM00041194   25.2550    55.3640       10.4                   DUBAI INTL   \n",
       " 4  AEM00041217   24.4330    54.6510       26.8               ABU DHABI INTL   \n",
       " \n",
       "   GSN_FLAG HCN_CRN_FLAG WMO_ID  \n",
       " 0      NaN          NaN    NaN  \n",
       " 1      NaN          NaN    NaN  \n",
       " 2      GSN          NaN  41196  \n",
       " 3      NaN          NaN  41194  \n",
       " 4      NaN          NaN  41217  ,\n",
       "             ID      LAT      LON ELEMENT  FIRSTYEAR  LASTYEAR\n",
       " 0  ACW00011604  17.1167 -61.7833    TMAX       1949      1949\n",
       " 1  ACW00011604  17.1167 -61.7833    TMIN       1949      1949\n",
       " 2  ACW00011604  17.1167 -61.7833    PRCP       1949      1949\n",
       " 3  ACW00011604  17.1167 -61.7833    SNOW       1949      1949\n",
       " 4  ACW00011604  17.1167 -61.7833    SNWD       1949      1949)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load Stations\n",
    "colspecs = [(0,11),(12,20),(21,30),(31,37),(38,40),(41,71),(72,75),(76,79),(80,85)]\n",
    "names = ['ID','LATITUDE','LONGITUDE','ELEVATION','STATE','NAME','GSN_FLAG','HCN_CRN_FLAG','WMO_ID']\n",
    "\n",
    "stations = pd.read_fwf(S3_STATIONS_TXT, colspecs=colspecs, names=names, dtype={'ID':str,'STATE':str,'WMO_ID':str}, storage_options=STOR)\n",
    "stations['NAME'] = stations['NAME'].str.strip(); stations['STATE'] = stations['STATE'].fillna('').str.strip()\n",
    "\n",
    "inventory = pd.read_csv(\n",
    "    S3_INVENTORY_TXT, sep=r'\\s+', names=['ID','LAT','LON','ELEMENT','FIRSTYEAR','LASTYEAR'],\n",
    "    dtype={'ID':str,'ELEMENT':str,'FIRSTYEAR':int,'LASTYEAR':int}, engine='python', storage_options=STOR\n",
    ")\n",
    "\n",
    "stations.head(), inventory.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "09c2d4ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_18404/1077117106.py:3: DtypeWarning: Columns (6) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(url, storage_options=STOR, dtype={'ID':str,'ELEMENT':str}, parse_dates=['DATE'])\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>ELEMENT</th>\n",
       "      <th>ID</th>\n",
       "      <th>DATE</th>\n",
       "      <th>DAPR</th>\n",
       "      <th>MDPR</th>\n",
       "      <th>PRCP</th>\n",
       "      <th>SNOW</th>\n",
       "      <th>SNWD</th>\n",
       "      <th>TMAX</th>\n",
       "      <th>TMIN</th>\n",
       "      <th>TOBS</th>\n",
       "      <th>WT01</th>\n",
       "      <th>WT03</th>\n",
       "      <th>WT04</th>\n",
       "      <th>WT06</th>\n",
       "      <th>WT08</th>\n",
       "      <th>WT11</th>\n",
       "      <th>WT14</th>\n",
       "      <th>WT16</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>46156</th>\n",
       "      <td>USC00087205</td>\n",
       "      <td>2025-12-05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>29.4</td>\n",
       "      <td>17.8</td>\n",
       "      <td>278.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46157</th>\n",
       "      <td>USC00087205</td>\n",
       "      <td>2025-12-06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28.3</td>\n",
       "      <td>20.6</td>\n",
       "      <td>278.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46158</th>\n",
       "      <td>USC00087205</td>\n",
       "      <td>2025-12-07</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28.3</td>\n",
       "      <td>15.6</td>\n",
       "      <td>217.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46159</th>\n",
       "      <td>USC00087205</td>\n",
       "      <td>2025-12-08</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>40.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24.4</td>\n",
       "      <td>17.2</td>\n",
       "      <td>239.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46160</th>\n",
       "      <td>USC00087205</td>\n",
       "      <td>2025-12-09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23.9</td>\n",
       "      <td>10.6</td>\n",
       "      <td>200.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "ELEMENT           ID       DATE  DAPR  MDPR  PRCP  SNOW  SNWD  TMAX  TMIN  \\\n",
       "46156    USC00087205 2025-12-05   NaN   NaN   0.0   NaN   NaN  29.4  17.8   \n",
       "46157    USC00087205 2025-12-06   NaN   NaN   0.0   NaN   NaN  28.3  20.6   \n",
       "46158    USC00087205 2025-12-07   NaN   NaN  18.5   NaN   NaN  28.3  15.6   \n",
       "46159    USC00087205 2025-12-08   NaN   NaN  40.6   NaN   NaN  24.4  17.2   \n",
       "46160    USC00087205 2025-12-09   NaN   NaN   0.3   NaN   NaN  23.9  10.6   \n",
       "\n",
       "ELEMENT   TOBS  WT01  WT03  WT04  WT06  WT08  WT11  WT14  WT16  \n",
       "46156    278.0   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "46157    278.0   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "46158    217.0   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "46159    239.0   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "46160    200.0   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load Station: USC00087205\n",
    "def load_station_daily(url: str) -> pd.DataFrame:\n",
    "    df = pd.read_csv(url, storage_options=STOR, dtype={'ID':str,'ELEMENT':str}, parse_dates=['DATE'])\n",
    "    df['DATA_VALUE'] = df['DATA_VALUE'].replace(-9999, np.nan)\n",
    "    wide = (df.pivot_table(index=['ID','DATE'], columns='ELEMENT', values='DATA_VALUE', aggfunc='first').reset_index())\n",
    "    for c in ('TMAX','TMIN','TAVG'):\n",
    "        if c in wide: wide[c] = wide[c]/10.0\n",
    "    if 'PRCP' in wide: wide['PRCP'] = wide['PRCP']/10.0\n",
    "    return wide.sort_values(['ID','DATE']).reset_index(drop=True)\n",
    "\n",
    "dt_daily = load_station_daily(S3_BY_STATION.format(id='USC00087205'))\n",
    "dt_daily.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbd0a0a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1 \n",
    "\n",
    "# Remove data that's not within 1991 and 2020\n",
    "\n",
    "dt_daily_30yrs = dt_daily.loc[dt_daily['DATE'].between('1991-01-01', '2020-12-31')].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d258612",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "142\n",
      "159\n"
     ]
    }
   ],
   "source": [
    "# Check if there are NaNs\n",
    "\n",
    "print(dt_daily_30yrs['TMAX'].isnull().sum()) \n",
    "print(dt_daily_30yrs['TMIN'].isnull().sum()) \n",
    "\n",
    "# Drop NaNs\n",
    "dt_daily_30yrs = dt_daily_30yrs.dropna(subset=['TMAX'])\n",
    "\n",
    "dt_daily_30yrs = dt_daily_30yrs.dropna(subset=['TMIN'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bd419916",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Year and Month from DATE Column\n",
    "\n",
    "dt_daily_30yrs['DATE'] = pd.to_datetime(dt_daily_30yrs['DATE'])\n",
    "dt_daily_30yrs['year'] = dt_daily_30yrs['DATE'].dt.year\n",
    "dt_daily_30yrs['month'] = dt_daily_30yrs['DATE'].dt.month\n",
    "\n",
    "# Get only the data from strawberry season\n",
    "dt_straw = dt_daily_30yrs[dt_daily_30yrs['month'].isin([1, 10, 11, 12])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "bc8b4a63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30.091666666666665\n",
      "30.091666666666665\n"
     ]
    }
   ],
   "source": [
    "# Risk Mean\n",
    "\n",
    "frost_days = (dt_straw['TMIN'] <=32).sum()\n",
    "freeze_days = (dt_straw['TMIN'] <=28).sum()\n",
    "\n",
    "# 4 months of the year for 30 years\n",
    "months = (30)*4\n",
    "\n",
    "# Frost - Risk Mean \n",
    "rm_frost = frost_days/months\n",
    "print(rm_frost)\n",
    "\n",
    "# Freeze - Risk Mean\n",
    "rm_freeze = freeze_days/months\n",
    "print(rm_freeze)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "2d3f7613",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I am getting the same value for both which seems wrong... I am going to move on in the intrest of time and maybe come back"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "6498b35a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_18404/1811308429.py:6: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  ds = pd.read_csv(url, delim_whitespace=True, comment='#', header=None)\n"
     ]
    }
   ],
   "source": [
    "#2\n",
    "\n",
    "# load file data\n",
    "url = \"https://www.cpc.ncep.noaa.gov/data/indices/sstoi.indices\"\n",
    "\n",
    "ds = pd.read_csv(url, delim_whitespace=True, comment='#', header=None)\n",
    "\n",
    "ds.columns = [\"YR\",\"MON\",\"NINO1+2\",\"ANOM1\",\"NINO3\",\"ANOM2\",\"NINO3.4\",\"ANOM3\",\"NINO4\",\"ANOM4\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e3728f7",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Unable to parse string \"YR\" at position 0",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/lib.pyx:2407\u001b[39m, in \u001b[36mpandas._libs.lib.maybe_convert_numeric\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mValueError\u001b[39m: Unable to parse string \"YR\"",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[75]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Update to strawberry season\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m ds[\u001b[33m'\u001b[39m\u001b[33mDATE\u001b[39m\u001b[33m'\u001b[39m] = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto_datetime\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43myear\u001b[49m\u001b[43m=\u001b[49m\u001b[43mds\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mYR\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmonth\u001b[49m\u001b[43m=\u001b[49m\u001b[43mds\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mMON\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mday\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      3\u001b[39m ds_straw = ds[\u001b[33m'\u001b[39m\u001b[33mtime\u001b[39m\u001b[33m'\u001b[39m].dt.month.isin([\u001b[32m10\u001b[39m,\u001b[32m11\u001b[39m,\u001b[32m12\u001b[39m,\u001b[32m1\u001b[39m])\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/envs/xarray-climate/lib/python3.13/site-packages/pandas/core/tools/datetimes.py:1075\u001b[39m, in \u001b[36mto_datetime\u001b[39m\u001b[34m(arg, errors, dayfirst, yearfirst, utc, format, exact, unit, infer_datetime_format, origin, cache)\u001b[39m\n\u001b[32m   1073\u001b[39m         result = arg._constructor(values, index=arg.index, name=arg.name)\n\u001b[32m   1074\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arg, (ABCDataFrame, abc.MutableMapping)):\n\u001b[32m-> \u001b[39m\u001b[32m1075\u001b[39m     result = \u001b[43m_assemble_from_unit_mappings\u001b[49m\u001b[43m(\u001b[49m\u001b[43marg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mutc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1076\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arg, Index):\n\u001b[32m   1077\u001b[39m     cache_array = _maybe_cache(arg, \u001b[38;5;28mformat\u001b[39m, cache, convert_listlike)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/envs/xarray-climate/lib/python3.13/site-packages/pandas/core/tools/datetimes.py:1214\u001b[39m, in \u001b[36m_assemble_from_unit_mappings\u001b[39m\u001b[34m(arg, errors, utc)\u001b[39m\n\u001b[32m   1210\u001b[39m         values = values.astype(\u001b[33m\"\u001b[39m\u001b[33mint64\u001b[39m\u001b[33m\"\u001b[39m, copy=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m   1211\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m values\n\u001b[32m   1213\u001b[39m values = (\n\u001b[32m-> \u001b[39m\u001b[32m1214\u001b[39m     \u001b[43mcoerce\u001b[49m\u001b[43m(\u001b[49m\u001b[43marg\u001b[49m\u001b[43m[\u001b[49m\u001b[43munit_rev\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43myear\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m * \u001b[32m10000\u001b[39m\n\u001b[32m   1215\u001b[39m     + coerce(arg[unit_rev[\u001b[33m\"\u001b[39m\u001b[33mmonth\u001b[39m\u001b[33m\"\u001b[39m]]) * \u001b[32m100\u001b[39m\n\u001b[32m   1216\u001b[39m     + coerce(arg[unit_rev[\u001b[33m\"\u001b[39m\u001b[33mday\u001b[39m\u001b[33m\"\u001b[39m]])\n\u001b[32m   1217\u001b[39m )\n\u001b[32m   1218\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1219\u001b[39m     values = to_datetime(values, \u001b[38;5;28mformat\u001b[39m=\u001b[33m\"\u001b[39m\u001b[33m%\u001b[39m\u001b[33mY\u001b[39m\u001b[33m%\u001b[39m\u001b[33mm\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[33m\"\u001b[39m, errors=errors, utc=utc)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/envs/xarray-climate/lib/python3.13/site-packages/pandas/core/tools/datetimes.py:1206\u001b[39m, in \u001b[36m_assemble_from_unit_mappings.<locals>.coerce\u001b[39m\u001b[34m(values)\u001b[39m\n\u001b[32m   1204\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcoerce\u001b[39m(values):\n\u001b[32m   1205\u001b[39m     \u001b[38;5;66;03m# we allow coercion to if errors allows\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1206\u001b[39m     values = \u001b[43mto_numeric\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1208\u001b[39m     \u001b[38;5;66;03m# prevent overflow in case of int8 or int16\u001b[39;00m\n\u001b[32m   1209\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m is_integer_dtype(values.dtype):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/envs/xarray-climate/lib/python3.13/site-packages/pandas/core/tools/numeric.py:235\u001b[39m, in \u001b[36mto_numeric\u001b[39m\u001b[34m(arg, errors, downcast, dtype_backend)\u001b[39m\n\u001b[32m    233\u001b[39m coerce_numeric = errors \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m (\u001b[33m\"\u001b[39m\u001b[33mignore\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mraise\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    234\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m235\u001b[39m     values, new_mask = \u001b[43mlib\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmaybe_convert_numeric\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[call-overload]\u001b[39;49;00m\n\u001b[32m    236\u001b[39m \u001b[43m        \u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    237\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mset\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    238\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcoerce_numeric\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcoerce_numeric\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    239\u001b[39m \u001b[43m        \u001b[49m\u001b[43mconvert_to_masked_nullable\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype_backend\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mlib\u001b[49m\u001b[43m.\u001b[49m\u001b[43mno_default\u001b[49m\n\u001b[32m    240\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mvalues_dtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mStringDtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    241\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;129;43;01mand\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mvalues_dtype\u001b[49m\u001b[43m.\u001b[49m\u001b[43mna_value\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mlibmissing\u001b[49m\u001b[43m.\u001b[49m\u001b[43mNA\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    242\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    243\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mValueError\u001b[39;00m, \u001b[38;5;167;01mTypeError\u001b[39;00m):\n\u001b[32m    244\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m errors == \u001b[33m\"\u001b[39m\u001b[33mraise\u001b[39m\u001b[33m\"\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/lib.pyx:2449\u001b[39m, in \u001b[36mpandas._libs.lib.maybe_convert_numeric\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mValueError\u001b[39m: Unable to parse string \"YR\" at position 0"
     ]
    }
   ],
   "source": [
    "# Update to strawberry season\n",
    "ds['DATE'] = pd.to_datetime(dict(year=ds['YR'], month=ds['MON'], day=1))\n",
    "ds_straw = ds['time'].dt.month.isin([10,11,12,1])\n",
    "\n",
    "# moving on because of time. I am not going to seperate this out into months to make it easier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "15b6e982",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'year'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[79]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m nino_yr = \u001b[43mds\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgroupby\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43myear\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m.mean().reset_index()\n\u001b[32m      2\u001b[39m nino_yr.head()\n\u001b[32m      4\u001b[39m freeze_data = dt_straw[dt_straw[\u001b[33m'\u001b[39m\u001b[33mTMIN\u001b[39m\u001b[33m'\u001b[39m] <= \u001b[32m28\u001b[39m].copy()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/envs/xarray-climate/lib/python3.13/site-packages/pandas/core/frame.py:9190\u001b[39m, in \u001b[36mDataFrame.groupby\u001b[39m\u001b[34m(self, by, axis, level, as_index, sort, group_keys, observed, dropna)\u001b[39m\n\u001b[32m   9187\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m level \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m by \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   9188\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mYou have to supply one of \u001b[39m\u001b[33m'\u001b[39m\u001b[33mby\u001b[39m\u001b[33m'\u001b[39m\u001b[33m and \u001b[39m\u001b[33m'\u001b[39m\u001b[33mlevel\u001b[39m\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m9190\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mDataFrameGroupBy\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   9191\u001b[39m \u001b[43m    \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   9192\u001b[39m \u001b[43m    \u001b[49m\u001b[43mkeys\u001b[49m\u001b[43m=\u001b[49m\u001b[43mby\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   9193\u001b[39m \u001b[43m    \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m=\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   9194\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   9195\u001b[39m \u001b[43m    \u001b[49m\u001b[43mas_index\u001b[49m\u001b[43m=\u001b[49m\u001b[43mas_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   9196\u001b[39m \u001b[43m    \u001b[49m\u001b[43msort\u001b[49m\u001b[43m=\u001b[49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   9197\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgroup_keys\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   9198\u001b[39m \u001b[43m    \u001b[49m\u001b[43mobserved\u001b[49m\u001b[43m=\u001b[49m\u001b[43mobserved\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   9199\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdropna\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdropna\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   9200\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/envs/xarray-climate/lib/python3.13/site-packages/pandas/core/groupby/groupby.py:1330\u001b[39m, in \u001b[36mGroupBy.__init__\u001b[39m\u001b[34m(self, obj, keys, axis, level, grouper, exclusions, selection, as_index, sort, group_keys, observed, dropna)\u001b[39m\n\u001b[32m   1327\u001b[39m \u001b[38;5;28mself\u001b[39m.dropna = dropna\n\u001b[32m   1329\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m grouper \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1330\u001b[39m     grouper, exclusions, obj = \u001b[43mget_grouper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1331\u001b[39m \u001b[43m        \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1332\u001b[39m \u001b[43m        \u001b[49m\u001b[43mkeys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1333\u001b[39m \u001b[43m        \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m=\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1334\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1335\u001b[39m \u001b[43m        \u001b[49m\u001b[43msort\u001b[49m\u001b[43m=\u001b[49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1336\u001b[39m \u001b[43m        \u001b[49m\u001b[43mobserved\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobserved\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mlib\u001b[49m\u001b[43m.\u001b[49m\u001b[43mno_default\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobserved\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1337\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdropna\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdropna\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1338\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1340\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m observed \u001b[38;5;129;01mis\u001b[39;00m lib.no_default:\n\u001b[32m   1341\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m(ping._passed_categorical \u001b[38;5;28;01mfor\u001b[39;00m ping \u001b[38;5;129;01min\u001b[39;00m grouper.groupings):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/envs/xarray-climate/lib/python3.13/site-packages/pandas/core/groupby/grouper.py:1043\u001b[39m, in \u001b[36mget_grouper\u001b[39m\u001b[34m(obj, key, axis, level, sort, observed, validate, dropna)\u001b[39m\n\u001b[32m   1041\u001b[39m         in_axis, level, gpr = \u001b[38;5;28;01mFalse\u001b[39;00m, gpr, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1042\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1043\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(gpr)\n\u001b[32m   1044\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(gpr, Grouper) \u001b[38;5;129;01mand\u001b[39;00m gpr.key \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   1045\u001b[39m     \u001b[38;5;66;03m# Add key to exclusions\u001b[39;00m\n\u001b[32m   1046\u001b[39m     exclusions.add(gpr.key)\n",
      "\u001b[31mKeyError\u001b[39m: 'year'"
     ]
    }
   ],
   "source": [
    "nino_yr = ds.groupby(\"year\").mean().reset_index()\n",
    "nino_yr.head()\n",
    "\n",
    "freeze_data = dt_straw[dt_straw['TMIN'] <= 28].copy()\n",
    "freeze_yearly = freeze_data.groupby(freeze_data['DATE'].dt.year).size().reset_index(name='freeze_days')\n",
    "freeze_yearly.rename(columns={'DATE': 'year'}, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e4c0ada",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_corr = pd.merge(freeze_yearly, nino_yr, on='year', how='inner')\n",
    "df_corr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f922f98",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import pearsonr\n",
    "\n",
    "for col in [\"NINO1+2\",\"NINO3\",\"NINO3.4\",\"NINO4\"]:\n",
    "    r, p = pearsonr(df_corr['freeze_days'], df_corr[col])\n",
    "    print(f\"{col}: r = {r:.3f}, p = {p:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e3dd836",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I have run out of time and cannot get this to run. If I could see the results then I would see which has the value\n",
    "# closest to one and that would have the strongest correlation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
